{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb6fd5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2799d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 , Loss: -0.046221017837524414\n",
      "Episode 1 , Loss: 0.0021431446075439453\n",
      "Episode 2 , Loss: -0.135903000831604\n",
      "Episode 3 , Loss: -0.04564619064331055\n",
      "Episode 4 , Loss: 0.03138303756713867\n",
      "Episode 5 , Loss: -0.0523756742477417\n",
      "Episode 6 , Loss: 0.07188558578491211\n",
      "Episode 7 , Loss: 0.08414971828460693\n",
      "Episode 8 , Loss: -0.0907902717590332\n",
      "Episode 9 , Loss: 0.12313699722290039\n",
      "Episode 10 , Loss: -0.04556405544281006\n",
      "Episode 11 , Loss: 0.08943355083465576\n",
      "Episode 12 , Loss: -0.07942783832550049\n",
      "Episode 13 , Loss: 0.09399676322937012\n",
      "Episode 14 , Loss: 0.03040444850921631\n",
      "Episode 15 , Loss: -0.28500354290008545\n",
      "Episode 16 , Loss: 0.06311023235321045\n",
      "Episode 17 , Loss: -0.023213982582092285\n",
      "Episode 18 , Loss: 0.04444706439971924\n",
      "Episode 19 , Loss: 0.007896065711975098\n",
      "Episode 20 , Loss: -0.14670145511627197\n",
      "Episode 21 , Loss: -0.07906579971313477\n",
      "Episode 22 , Loss: -0.11578667163848877\n",
      "Episode 23 , Loss: -0.005194425582885742\n",
      "Episode 24 , Loss: 0.0058133602142333984\n",
      "Episode 25 , Loss: 0.031410932540893555\n",
      "Episode 26 , Loss: -0.03135204315185547\n",
      "Episode 27 , Loss: 0.06181526184082031\n",
      "Episode 28 , Loss: -0.049965500831604004\n",
      "Episode 29 , Loss: 0.1591416597366333\n",
      "Episode 30 , Loss: 0.02989518642425537\n",
      "Episode 31 , Loss: -0.014150381088256836\n",
      "Episode 32 , Loss: -0.021389245986938477\n",
      "Episode 33 , Loss: 0.05955767631530762\n",
      "Episode 34 , Loss: -0.0019136667251586914\n",
      "Episode 35 , Loss: 0.11542415618896484\n",
      "Episode 36 , Loss: -0.2775064706802368\n",
      "Episode 37 , Loss: -0.02200031280517578\n",
      "Episode 38 , Loss: -0.035077452659606934\n",
      "Episode 39 , Loss: 0.010176658630371094\n",
      "Episode 40 , Loss: 0.018422842025756836\n",
      "Episode 41 , Loss: -0.11549139022827148\n",
      "Episode 42 , Loss: -0.027680516242980957\n",
      "Episode 43 , Loss: -0.01996588706970215\n",
      "Episode 44 , Loss: 0.07729613780975342\n",
      "Episode 45 , Loss: 0.07378590106964111\n",
      "Episode 46 , Loss: -0.058739542961120605\n",
      "Episode 47 , Loss: 0.031081199645996094\n",
      "Episode 48 , Loss: 0.004973292350769043\n",
      "Episode 49 , Loss: -0.02494823932647705\n",
      "Episode 50 , Loss: 0.048195481300354004\n",
      "Episode 51 , Loss: -0.16498279571533203\n",
      "Episode 52 , Loss: -0.15630567073822021\n",
      "Episode 53 , Loss: -0.25438618659973145\n",
      "Episode 54 , Loss: -0.022754430770874023\n",
      "Episode 55 , Loss: -0.05040264129638672\n",
      "Episode 56 , Loss: -0.025005459785461426\n",
      "Episode 57 , Loss: 0.012858152389526367\n",
      "Episode 58 , Loss: -0.10268282890319824\n",
      "Episode 59 , Loss: -0.10126376152038574\n",
      "Episode 60 , Loss: -0.05319774150848389\n",
      "Episode 61 , Loss: -0.008207440376281738\n",
      "Episode 62 , Loss: -0.0391618013381958\n",
      "Episode 63 , Loss: -0.0831756591796875\n",
      "Episode 64 , Loss: 0.03458690643310547\n",
      "Episode 65 , Loss: 0.05246114730834961\n",
      "Episode 66 , Loss: 0.04912769794464111\n",
      "Episode 67 , Loss: -0.24986302852630615\n",
      "Episode 68 , Loss: -0.033659934997558594\n",
      "Episode 69 , Loss: 0.019251465797424316\n",
      "Episode 70 , Loss: -0.01403343677520752\n",
      "Episode 71 , Loss: -0.11106538772583008\n",
      "Episode 72 , Loss: -0.028657913208007812\n",
      "Episode 73 , Loss: 0.15452241897583008\n",
      "Episode 74 , Loss: 0.03448963165283203\n",
      "Episode 75 , Loss: -0.3043365478515625\n",
      "Episode 76 , Loss: 0.12628841400146484\n",
      "Episode 77 , Loss: 0.0010292530059814453\n",
      "Episode 78 , Loss: -0.15926218032836914\n",
      "Episode 79 , Loss: 0.1299750804901123\n",
      "Episode 80 , Loss: 0.05292856693267822\n",
      "Episode 81 , Loss: -0.05055582523345947\n",
      "Episode 82 , Loss: 0.016203641891479492\n",
      "Episode 83 , Loss: -0.025406837463378906\n",
      "Episode 84 , Loss: -0.03042125701904297\n",
      "Episode 85 , Loss: -0.03733634948730469\n",
      "Episode 86 , Loss: -0.07654619216918945\n",
      "Episode 87 , Loss: -0.03554975986480713\n",
      "Episode 88 , Loss: -0.07789933681488037\n",
      "Episode 89 , Loss: -0.0317000150680542\n",
      "Episode 90 , Loss: 0.10548663139343262\n",
      "Episode 91 , Loss: 0.03593742847442627\n",
      "Episode 92 , Loss: 0.04048025608062744\n",
      "Episode 93 , Loss: -0.033692240715026855\n",
      "Episode 94 , Loss: 0.016008496284484863\n",
      "Episode 95 , Loss: -0.014071941375732422\n",
      "Episode 96 , Loss: -0.1210331916809082\n",
      "Episode 97 , Loss: -0.06582272052764893\n",
      "Episode 98 , Loss: 0.033533692359924316\n",
      "Episode 99 , Loss: -0.16871190071105957\n",
      "Episode 100 , Loss: -0.08718633651733398\n",
      "Episode 101 , Loss: -0.2435380220413208\n",
      "Episode 102 , Loss: 0.11810958385467529\n",
      "Episode 103 , Loss: 0.01712620258331299\n",
      "Episode 104 , Loss: -0.2784305810928345\n",
      "Episode 105 , Loss: -0.05602717399597168\n",
      "Episode 106 , Loss: 0.012279510498046875\n",
      "Episode 107 , Loss: -0.001755356788635254\n",
      "Episode 108 , Loss: -0.12039542198181152\n",
      "Episode 109 , Loss: -0.12614476680755615\n",
      "Episode 110 , Loss: -0.1314253807067871\n",
      "Episode 111 , Loss: -0.08032208681106567\n",
      "Episode 112 , Loss: -0.06666374206542969\n",
      "Episode 113 , Loss: -0.15454614162445068\n",
      "Episode 114 , Loss: -0.1087425947189331\n",
      "Episode 115 , Loss: 0.22574961185455322\n",
      "Episode 116 , Loss: 0.39596450328826904\n",
      "Episode 117 , Loss: -0.06662583351135254\n",
      "Episode 118 , Loss: -0.18854737281799316\n",
      "Episode 119 , Loss: 0.03877270221710205\n",
      "Episode 120 , Loss: -0.09901058673858643\n",
      "Episode 121 , Loss: -0.35871613025665283\n",
      "Episode 122 , Loss: -0.013179659843444824\n",
      "Episode 123 , Loss: -0.07476949691772461\n",
      "Episode 124 , Loss: -0.06387925148010254\n",
      "Episode 125 , Loss: 0.09811091423034668\n",
      "Episode 126 , Loss: 0.059564948081970215\n",
      "Episode 127 , Loss: 0.1227424144744873\n",
      "Episode 128 , Loss: 0.018823862075805664\n",
      "Episode 129 , Loss: -0.2950153350830078\n",
      "Episode 130 , Loss: -0.16875004768371582\n",
      "Episode 131 , Loss: -0.12703871726989746\n",
      "Episode 132 , Loss: -0.18844783306121826\n",
      "Episode 133 , Loss: -0.23655354976654053\n",
      "Episode 134 , Loss: -0.06938576698303223\n",
      "Episode 135 , Loss: -0.39736104011535645\n",
      "Episode 136 , Loss: -0.11889910697937012\n",
      "Episode 137 , Loss: 0.0019315481185913086\n",
      "Episode 138 , Loss: 0.04925179481506348\n",
      "Episode 139 , Loss: 0.18233120441436768\n",
      "Episode 140 , Loss: 0.057857632637023926\n",
      "Episode 141 , Loss: -0.038930654525756836\n",
      "Episode 142 , Loss: -0.2165001630783081\n",
      "Episode 143 , Loss: -0.028751492500305176\n",
      "Episode 144 , Loss: -0.5178860425949097\n",
      "Episode 145 , Loss: 0.03783690929412842\n",
      "Episode 146 , Loss: -0.09517025947570801\n",
      "Episode 147 , Loss: 0.04469621181488037\n",
      "Episode 148 , Loss: 0.09506571292877197\n",
      "Episode 149 , Loss: -0.32987332344055176\n",
      "Episode 150 , Loss: -0.4103813171386719\n",
      "Episode 151 , Loss: 0.1303156614303589\n",
      "Episode 152 , Loss: -0.05149507522583008\n",
      "Episode 153 , Loss: -0.08707380294799805\n",
      "Episode 154 , Loss: 0.02895057201385498\n",
      "Episode 155 , Loss: -0.3398653268814087\n",
      "Episode 156 , Loss: 0.04250061511993408\n",
      "Episode 157 , Loss: -0.14813268184661865\n",
      "Episode 158 , Loss: -0.19475984573364258\n",
      "Episode 159 , Loss: -0.012190103530883789\n",
      "Episode 160 , Loss: 0.2716275453567505\n",
      "Episode 161 , Loss: -0.041529178619384766\n",
      "Episode 162 , Loss: 0.02482551336288452\n",
      "Episode 163 , Loss: -0.05732095241546631\n",
      "Episode 164 , Loss: -0.17547821998596191\n",
      "Episode 165 , Loss: -0.14495909214019775\n",
      "Episode 166 , Loss: -0.19144511222839355\n",
      "Episode 167 , Loss: 0.026389479637145996\n",
      "Episode 168 , Loss: -0.18842792510986328\n",
      "Episode 169 , Loss: 0.17688894271850586\n",
      "Episode 170 , Loss: -0.6098670959472656\n",
      "Episode 171 , Loss: -0.1915220022201538\n",
      "Episode 172 , Loss: -0.6123951077461243\n",
      "Episode 173 , Loss: -0.11930215358734131\n",
      "Episode 174 , Loss: -0.32620155811309814\n",
      "Episode 175 , Loss: -0.2153099775314331\n",
      "Episode 176 , Loss: 0.14517629146575928\n",
      "Episode 177 , Loss: 0.020971298217773438\n",
      "Episode 178 , Loss: 0.07926130294799805\n",
      "Episode 179 , Loss: -0.4458777904510498\n",
      "Episode 180 , Loss: -0.19084501266479492\n",
      "Episode 181 , Loss: 0.12397360801696777\n",
      "Episode 182 , Loss: -0.3171732425689697\n",
      "Episode 183 , Loss: 0.4008216857910156\n",
      "Episode 184 , Loss: -0.06278014183044434\n",
      "Episode 185 , Loss: -0.6867815256118774\n",
      "Episode 186 , Loss: 0.3999173641204834\n",
      "Episode 187 , Loss: -0.17838054895401\n",
      "Episode 188 , Loss: -0.13585591316223145\n",
      "Episode 189 , Loss: -0.20601433515548706\n",
      "Episode 190 , Loss: 0.2172260284423828\n",
      "Episode 191 , Loss: -0.3353313207626343\n",
      "Episode 192 , Loss: -0.03293967247009277\n",
      "Episode 193 , Loss: 0.41792672872543335\n",
      "Episode 194 , Loss: 0.24191802740097046\n",
      "Episode 195 , Loss: -0.08088421821594238\n",
      "Episode 196 , Loss: -0.3270149230957031\n",
      "Episode 197 , Loss: 0.21590900421142578\n",
      "Episode 198 , Loss: -1.080665111541748\n",
      "Episode 199 , Loss: 0.2872964143753052\n",
      "Episode 200 , Loss: -0.779267430305481\n",
      "Episode 201 , Loss: 0.17486584186553955\n",
      "Episode 202 , Loss: -0.4453376531600952\n",
      "Episode 203 , Loss: -0.38810861110687256\n",
      "Episode 204 , Loss: -0.6954776048660278\n",
      "Episode 205 , Loss: -0.3445512056350708\n",
      "Episode 206 , Loss: -0.21124929189682007\n",
      "Episode 207 , Loss: -0.4617919325828552\n",
      "Episode 208 , Loss: -0.1867830753326416\n",
      "Episode 209 , Loss: -0.3126868009567261\n",
      "Episode 210 , Loss: -0.9467775821685791\n",
      "Episode 211 , Loss: -0.29081523418426514\n",
      "Episode 212 , Loss: -0.1987628936767578\n",
      "Episode 213 , Loss: -0.46143579483032227\n",
      "Episode 214 , Loss: 0.2746695876121521\n",
      "Episode 215 , Loss: -1.2055591344833374\n",
      "Episode 216 , Loss: -1.663014531135559\n",
      "Episode 217 , Loss: 0.3662374019622803\n",
      "Episode 218 , Loss: -0.18711167573928833\n",
      "Episode 219 , Loss: 0.1599482297897339\n",
      "Episode 220 , Loss: -0.3205057382583618\n",
      "Episode 221 , Loss: 0.49836260080337524\n",
      "Episode 222 , Loss: -0.1586601734161377\n",
      "Episode 223 , Loss: -0.13985663652420044\n",
      "Episode 224 , Loss: -0.095772385597229\n",
      "Episode 225 , Loss: -0.2709228992462158\n",
      "Episode 226 , Loss: 0.13429969549179077\n",
      "Episode 227 , Loss: 0.25486552715301514\n",
      "Episode 228 , Loss: -1.7578383684158325\n",
      "Episode 229 , Loss: 0.032422423362731934\n",
      "Episode 230 , Loss: -1.0481936931610107\n",
      "Episode 231 , Loss: -0.21725362539291382\n",
      "Episode 232 , Loss: 0.14724218845367432\n",
      "Episode 233 , Loss: -1.021634578704834\n",
      "Episode 234 , Loss: 1.3076248168945312\n",
      "Episode 235 , Loss: 0.34852463006973267\n",
      "Episode 236 , Loss: -0.3089890480041504\n",
      "Episode 237 , Loss: -1.1888742446899414\n",
      "Episode 238 , Loss: -0.10379433631896973\n",
      "Episode 239 , Loss: -0.7673255801200867\n",
      "Episode 240 , Loss: -1.0504157543182373\n",
      "Episode 241 , Loss: -0.8838601112365723\n",
      "Episode 242 , Loss: 0.058118343353271484\n",
      "Episode 243 , Loss: 0.1575547456741333\n",
      "Episode 244 , Loss: -0.16797596216201782\n",
      "Episode 245 , Loss: 0.0541532039642334\n",
      "Episode 246 , Loss: -1.6253304481506348\n",
      "Episode 247 , Loss: 1.414745807647705\n",
      "Episode 248 , Loss: 0.813601016998291\n",
      "Episode 249 , Loss: -0.33725136518478394\n",
      "Episode 250 , Loss: 0.5291044116020203\n",
      "Episode 251 , Loss: -0.47268033027648926\n",
      "Episode 252 , Loss: 0.11845618486404419\n",
      "Episode 253 , Loss: -0.9073556661605835\n",
      "Episode 254 , Loss: -0.2083032727241516\n",
      "Episode 255 , Loss: -0.44050395488739014\n",
      "Episode 256 , Loss: -0.0684964656829834\n",
      "Episode 257 , Loss: -0.2851308584213257\n",
      "Episode 258 , Loss: -0.2771115303039551\n",
      "Episode 259 , Loss: 0.06372475624084473\n",
      "Episode 260 , Loss: 0.23290926218032837\n",
      "Episode 261 , Loss: 0.09639054536819458\n",
      "Episode 262 , Loss: -1.178038239479065\n",
      "Episode 263 , Loss: -0.7354223728179932\n",
      "Episode 264 , Loss: 0.25075507164001465\n",
      "Episode 265 , Loss: 0.1346747875213623\n",
      "Episode 266 , Loss: -0.8766491413116455\n",
      "Episode 267 , Loss: -0.3577118515968323\n",
      "Episode 268 , Loss: 0.559448778629303\n",
      "Episode 269 , Loss: -1.4514166116714478\n",
      "Episode 270 , Loss: -1.8563921451568604\n",
      "Episode 271 , Loss: -0.23673784732818604\n",
      "Episode 272 , Loss: -0.32248741388320923\n",
      "Episode 273 , Loss: 0.3967524766921997\n",
      "Episode 274 , Loss: -0.054854393005371094\n",
      "Episode 275 , Loss: -1.44711434841156\n",
      "Episode 276 , Loss: 0.42757678031921387\n",
      "Episode 277 , Loss: 0.38469576835632324\n",
      "Episode 278 , Loss: 0.13868725299835205\n",
      "Episode 279 , Loss: -0.4109690189361572\n",
      "Episode 280 , Loss: -1.859485387802124\n",
      "Episode 281 , Loss: -1.2577719688415527\n",
      "Episode 282 , Loss: 0.23209315538406372\n",
      "Episode 283 , Loss: 0.4710720181465149\n",
      "Episode 284 , Loss: -0.5874443054199219\n",
      "Episode 285 , Loss: 0.5373510718345642\n",
      "Episode 286 , Loss: 0.349945604801178\n",
      "Episode 287 , Loss: 0.308671772480011\n",
      "Episode 288 , Loss: 0.14385062456130981\n",
      "Episode 289 , Loss: -3.767035722732544\n",
      "Episode 290 , Loss: 0.9788292050361633\n",
      "Episode 291 , Loss: -2.0120861530303955\n",
      "Episode 292 , Loss: -2.211608409881592\n",
      "Episode 293 , Loss: -0.9100821018218994\n",
      "Episode 294 , Loss: -0.055576324462890625\n",
      "Episode 295 , Loss: 1.0340157747268677\n",
      "Episode 296 , Loss: 0.18244296312332153\n",
      "Episode 297 , Loss: 0.5059322118759155\n",
      "Episode 298 , Loss: -0.10869860649108887\n",
      "Episode 299 , Loss: 0.035674214363098145\n",
      "Episode 300 , Loss: -0.8086520433425903\n",
      "Episode 301 , Loss: -0.9122266173362732\n",
      "Episode 302 , Loss: -2.1956207752227783\n",
      "Episode 303 , Loss: -1.1451969146728516\n",
      "Episode 304 , Loss: -0.20857828855514526\n",
      "Episode 305 , Loss: -0.03975933790206909\n",
      "Episode 306 , Loss: 1.9333868026733398\n",
      "Episode 307 , Loss: -0.1819016933441162\n",
      "Episode 308 , Loss: -0.2826431393623352\n",
      "Episode 309 , Loss: -0.27447545528411865\n",
      "Episode 310 , Loss: 0.678817093372345\n",
      "Episode 311 , Loss: 0.5382498502731323\n",
      "Episode 312 , Loss: 1.4923927783966064\n",
      "Episode 313 , Loss: 1.3247044086456299\n",
      "Episode 314 , Loss: -1.9725534915924072\n",
      "Episode 315 , Loss: -0.5733144283294678\n",
      "Episode 316 , Loss: -1.2152595520019531\n",
      "Episode 317 , Loss: -0.2907230854034424\n",
      "Episode 318 , Loss: 0.035917818546295166\n",
      "Episode 319 , Loss: -1.7180083990097046\n",
      "Episode 320 , Loss: -2.2223877906799316\n",
      "Episode 321 , Loss: -1.364579200744629\n",
      "Episode 322 , Loss: -0.6902762055397034\n",
      "Episode 323 , Loss: -0.6133828163146973\n",
      "Episode 324 , Loss: 0.8704876899719238\n",
      "Episode 325 , Loss: -0.0815885066986084\n",
      "Episode 326 , Loss: 0.752173900604248\n",
      "Episode 327 , Loss: -1.0104434490203857\n",
      "Episode 328 , Loss: 0.17502570152282715\n",
      "Episode 329 , Loss: 1.4157164096832275\n",
      "Episode 330 , Loss: 0.008550941944122314\n",
      "Episode 331 , Loss: -0.6871335506439209\n",
      "Episode 332 , Loss: 0.5824375152587891\n",
      "Episode 333 , Loss: -2.443060874938965\n",
      "Episode 334 , Loss: -1.364292860031128\n",
      "Episode 335 , Loss: -1.183375358581543\n",
      "Episode 336 , Loss: -1.2576279640197754\n",
      "Episode 337 , Loss: 1.7745335102081299\n",
      "Episode 338 , Loss: 0.5076568126678467\n",
      "Episode 339 , Loss: -1.556973934173584\n",
      "Episode 340 , Loss: 1.363068699836731\n",
      "Episode 341 , Loss: 0.7542390823364258\n",
      "Episode 342 , Loss: -1.9242222309112549\n",
      "Episode 343 , Loss: 0.014660656452178955\n",
      "Episode 344 , Loss: -0.3345922827720642\n",
      "Episode 345 , Loss: -0.7775570154190063\n",
      "Episode 346 , Loss: -0.9317870140075684\n",
      "Episode 347 , Loss: 1.5621328353881836\n",
      "Episode 348 , Loss: 1.2490164041519165\n",
      "Episode 349 , Loss: -1.3267004489898682\n",
      "Episode 350 , Loss: -0.4009682536125183\n",
      "Episode 351 , Loss: 0.12417227029800415\n",
      "Episode 352 , Loss: 2.2525405883789062\n",
      "Episode 353 , Loss: -3.3948073387145996\n",
      "Episode 354 , Loss: -1.4740132093429565\n",
      "Episode 355 , Loss: 0.3442651033401489\n",
      "Episode 356 , Loss: -0.7707640528678894\n",
      "Episode 357 , Loss: 0.6670580506324768\n",
      "Episode 358 , Loss: -0.9236985445022583\n",
      "Episode 359 , Loss: -1.378709316253662\n",
      "Episode 360 , Loss: -1.5461244583129883\n",
      "Episode 361 , Loss: -0.8224437236785889\n",
      "Episode 362 , Loss: -0.5131436586380005\n",
      "Episode 363 , Loss: -1.320891261100769\n",
      "Episode 364 , Loss: -1.0023043155670166\n",
      "Episode 365 , Loss: -0.6177607178688049\n",
      "Episode 366 , Loss: -1.5773495435714722\n",
      "Episode 367 , Loss: -1.0200414657592773\n",
      "Episode 368 , Loss: -3.0040533542633057\n",
      "Episode 369 , Loss: -0.9993396997451782\n",
      "Episode 370 , Loss: 1.5226130485534668\n",
      "Episode 371 , Loss: 0.6387802958488464\n",
      "Episode 372 , Loss: -2.591127395629883\n",
      "Episode 373 , Loss: -1.8926117420196533\n",
      "Episode 374 , Loss: -1.6814279556274414\n",
      "Episode 375 , Loss: -1.5846550464630127\n",
      "Episode 376 , Loss: -2.2746121883392334\n",
      "Episode 377 , Loss: -3.1369171142578125\n",
      "Episode 378 , Loss: -1.665789008140564\n",
      "Episode 379 , Loss: -0.9711370468139648\n",
      "Episode 380 , Loss: -3.8101325035095215\n",
      "Episode 381 , Loss: 1.9667744636535645\n",
      "Episode 382 , Loss: -2.2658932209014893\n",
      "Episode 383 , Loss: -0.058826744556427\n",
      "Episode 384 , Loss: -2.8415491580963135\n",
      "Episode 385 , Loss: -1.1209399700164795\n",
      "Episode 386 , Loss: -0.1908980906009674\n",
      "Episode 387 , Loss: -2.0502572059631348\n",
      "Episode 388 , Loss: -0.2510344982147217\n",
      "Episode 389 , Loss: -4.046972751617432\n",
      "Episode 390 , Loss: -2.3397762775421143\n",
      "Episode 391 , Loss: -2.4819111824035645\n",
      "Episode 392 , Loss: -0.3863869905471802\n",
      "Episode 393 , Loss: -3.002584457397461\n",
      "Episode 394 , Loss: -0.5208437442779541\n",
      "Episode 395 , Loss: -2.6424548625946045\n",
      "Episode 396 , Loss: -2.0423901081085205\n",
      "Episode 397 , Loss: -8.353324890136719\n",
      "Episode 398 , Loss: 0.08071017265319824\n",
      "Episode 399 , Loss: 0.47259455919265747\n",
      "Episode 400 , Loss: 0.5710800290107727\n",
      "Episode 401 , Loss: 1.8639076948165894\n",
      "Episode 402 , Loss: 0.8641881942749023\n",
      "Episode 403 , Loss: -2.9200854301452637\n",
      "Episode 404 , Loss: -1.9396638870239258\n",
      "Episode 405 , Loss: -3.5496621131896973\n",
      "Episode 406 , Loss: 1.4107145071029663\n",
      "Episode 407 , Loss: -3.2552905082702637\n",
      "Episode 408 , Loss: -7.496795177459717\n",
      "Episode 409 , Loss: -2.8647851943969727\n",
      "Episode 410 , Loss: 2.7136809825897217\n",
      "Episode 411 , Loss: -3.7412831783294678\n",
      "Episode 412 , Loss: -3.121877431869507\n",
      "Episode 413 , Loss: 0.2984842360019684\n",
      "Episode 414 , Loss: -4.5607404708862305\n",
      "Episode 415 , Loss: 1.6790496110916138\n",
      "Episode 416 , Loss: -0.9323058128356934\n",
      "Episode 417 , Loss: -0.614610493183136\n",
      "Episode 418 , Loss: -0.6524479389190674\n",
      "Episode 419 , Loss: 2.0355043411254883\n",
      "Episode 420 , Loss: -2.444568634033203\n",
      "Episode 421 , Loss: -0.7432213425636292\n",
      "Episode 422 , Loss: -2.978569269180298\n",
      "Episode 423 , Loss: -1.4947245121002197\n",
      "Episode 424 , Loss: -7.505094528198242\n",
      "Episode 425 , Loss: -0.2162923514842987\n",
      "Episode 426 , Loss: -5.237795829772949\n",
      "Episode 427 , Loss: -3.6112473011016846\n",
      "Episode 428 , Loss: -14.765810012817383\n",
      "Episode 429 , Loss: -6.737751483917236\n",
      "Episode 430 , Loss: -1.796684980392456\n",
      "Episode 431 , Loss: -4.791531562805176\n",
      "Episode 432 , Loss: -0.7214633822441101\n",
      "Episode 433 , Loss: -0.5354118347167969\n",
      "Episode 434 , Loss: -0.9533851742744446\n",
      "Episode 435 , Loss: 3.725175142288208\n",
      "Episode 436 , Loss: -1.167893648147583\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m observations.append(obs)\n\u001b[32m     48\u001b[39m actions.append(action)\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m obs , reward , terminated , truncated , info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m obs = torch.tensor(obs,dtype=torch.float32)\n\u001b[32m     52\u001b[39m rewards.append(reward)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:125\u001b[39m, in \u001b[36mTimeLimit.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    114\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m \n\u001b[32m    124\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mself\u001b[39m._elapsed_steps += \u001b[32m1\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elapsed_steps >= \u001b[38;5;28mself\u001b[39m._max_episode_steps:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[39m, in \u001b[36mOrderEnforcing.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[33m\"\u001b[39m\u001b[33mCannot call env.step() before calling env.reset()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:285\u001b[39m, in \u001b[36mPassiveEnvChecker.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m.env, action)\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:223\u001b[39m, in \u001b[36mCartPoleEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    220\u001b[39m     reward = -\u001b[32m1.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sutton_barto_reward \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.render_mode == \u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# truncation=False as the time limit is handled by the `TimeLimit` wrapper added during `make`\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.array(\u001b[38;5;28mself\u001b[39m.state, dtype=np.float32), reward, terminated, \u001b[38;5;28;01mFalse\u001b[39;00m, {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:299\u001b[39m, in \u001b[36mCartPoleEnv.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    297\u001b[39m cart_coords = [(c[\u001b[32m0\u001b[39m] + cartx, c[\u001b[32m1\u001b[39m] + carty) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m cart_coords]\n\u001b[32m    298\u001b[39m gfxdraw.aapolygon(\u001b[38;5;28mself\u001b[39m.surf, cart_coords, (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m \u001b[43mgfxdraw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilled_polygon\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msurf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcart_coords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    301\u001b[39m l, r, t, b = (\n\u001b[32m    302\u001b[39m     -polewidth / \u001b[32m2\u001b[39m,\n\u001b[32m    303\u001b[39m     polewidth / \u001b[32m2\u001b[39m,\n\u001b[32m    304\u001b[39m     polelen - polewidth / \u001b[32m2\u001b[39m,\n\u001b[32m    305\u001b[39m     -polewidth / \u001b[32m2\u001b[39m,\n\u001b[32m    306\u001b[39m )\n\u001b[32m    308\u001b[39m pole_coords = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "env  = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "obs , info = env.reset(seed=42)\n",
    "obs = torch.tensor(obs) \n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.core = nn.Sequential(\n",
    "            nn.Linear(4,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,2),\n",
    "           \n",
    "            \n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.core(x)\n",
    "    \n",
    "policy = Policy()\n",
    "\n",
    "episodes = 1000\n",
    "gamma = 0.99\n",
    "optimizer = torch.optim.Adam(policy.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    obs , info = env.reset()\n",
    "    obs = torch.tensor(obs,dtype=torch.float32)\n",
    "    done = False \n",
    "    observations = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    \n",
    "    while not done :\n",
    "        logits = policy(obs)\n",
    "        probs = torch.softmax(logits , dim=-1)\n",
    "        action = torch.multinomial(probs,num_samples=1).item()\n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "        \n",
    "        obs , reward , terminated , truncated , info = env.step (action)\n",
    "        obs = torch.tensor(obs,dtype=torch.float32)\n",
    "        rewards.append(reward)\n",
    "        done = terminated or truncated\n",
    "    Gs = []\n",
    "    G = 0\n",
    "    for i in range(len(rewards) - 1 , -1 , -1):\n",
    "        G = rewards[i] + gamma * G\n",
    "        Gs.append(G)\n",
    "    Gs.reverse()\n",
    "    Gs = torch.tensor(Gs,dtype=torch.float32)\n",
    "    Gs = (Gs - Gs.mean()) / (Gs.std(unbiased=False) + 1e-8)\n",
    "\n",
    "    loss = 0 \n",
    "    for obs, action , G in zip(observations , actions , Gs):\n",
    "        logits = policy(obs)\n",
    "        probs = torch.softmax(logits, dim =-1)\n",
    "\n",
    "        max_prob = probs[action]\n",
    "      \n",
    "        log_prob = torch.log(max_prob)\n",
    "        loss += -log_prob * G \n",
    "    print(f\"Episode {episode} , Loss: {loss.item()}\")\n",
    "    loss /= len(observations)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(policy.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "   \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff7383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
