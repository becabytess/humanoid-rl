{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3facf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "import torch \n",
    "from copy import deepcopy\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.core = nn.Sequential(\n",
    "            nn.Linear(4,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,2)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.core(x)\n",
    "\n",
    "\n",
    "class Value(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.core = nn.Sequential(\n",
    "            nn.Linear(4,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,1)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.core(x)\n",
    "\n",
    "\n",
    "policyModel = Policy()\n",
    "\n",
    "oldPolicyModel = deepcopy(policyModel)\n",
    "def update_old_policy():\n",
    "    global oldPolicyModel\n",
    "    oldPolicyModel = deepcopy(policyModel)\n",
    "    for param in oldPolicyModel.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "valueModel = Value()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "711bde48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym \n",
    "\n",
    "\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "ppo_epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6464bdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:214: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  1  loss:  tensor([2.1674e-08], grad_fn=<DivBackward0>)\n",
      "episode:  2  loss:  tensor([-0.0029], grad_fn=<DivBackward0>)\n",
      "episode:  3  loss:  tensor([0.0117], grad_fn=<DivBackward0>)\n",
      "episode:  4  loss:  tensor([-0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  5  loss:  tensor([-4.1977e-05], grad_fn=<DivBackward0>)\n",
      "episode:  6  loss:  tensor([-0.0043], grad_fn=<DivBackward0>)\n",
      "episode:  7  loss:  tensor([-0.0055], grad_fn=<DivBackward0>)\n",
      "episode:  8  loss:  tensor([0.0235], grad_fn=<DivBackward0>)\n",
      "episode:  9  loss:  tensor([0.0057], grad_fn=<DivBackward0>)\n",
      "episode:  10  loss:  tensor([0.0232], grad_fn=<DivBackward0>)\n",
      "episode:  11  loss:  tensor([1.9463e-08], grad_fn=<DivBackward0>)\n",
      "episode:  12  loss:  tensor([0.0152], grad_fn=<DivBackward0>)\n",
      "episode:  13  loss:  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "episode:  14  loss:  tensor([-0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  15  loss:  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  16  loss:  tensor([-0.0009], grad_fn=<DivBackward0>)\n",
      "episode:  17  loss:  tensor([-0.0052], grad_fn=<DivBackward0>)\n",
      "episode:  18  loss:  tensor([0.0081], grad_fn=<DivBackward0>)\n",
      "episode:  19  loss:  tensor([0.0039], grad_fn=<DivBackward0>)\n",
      "episode:  20  loss:  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "episode:  21  loss:  tensor([-6.7733e-09], grad_fn=<DivBackward0>)\n",
      "episode:  22  loss:  tensor([-0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  23  loss:  tensor([-0.0023], grad_fn=<DivBackward0>)\n",
      "episode:  24  loss:  tensor([-0.0031], grad_fn=<DivBackward0>)\n",
      "episode:  25  loss:  tensor([0.0023], grad_fn=<DivBackward0>)\n",
      "episode:  26  loss:  tensor([-0.0039], grad_fn=<DivBackward0>)\n",
      "episode:  27  loss:  tensor([0.0094], grad_fn=<DivBackward0>)\n",
      "episode:  28  loss:  tensor([0.0023], grad_fn=<DivBackward0>)\n",
      "episode:  29  loss:  tensor([0.0053], grad_fn=<DivBackward0>)\n",
      "episode:  30  loss:  tensor([0.0026], grad_fn=<DivBackward0>)\n",
      "episode:  31  loss:  tensor([6.2377e-08], grad_fn=<DivBackward0>)\n",
      "episode:  32  loss:  tensor([-0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  33  loss:  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  34  loss:  tensor([-0.0017], grad_fn=<DivBackward0>)\n",
      "episode:  35  loss:  tensor([0.0043], grad_fn=<DivBackward0>)\n",
      "episode:  36  loss:  tensor([0.0013], grad_fn=<DivBackward0>)\n",
      "episode:  37  loss:  tensor([-0.0012], grad_fn=<DivBackward0>)\n",
      "episode:  38  loss:  tensor([-0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  39  loss:  tensor([0.0029], grad_fn=<DivBackward0>)\n",
      "episode:  40  loss:  tensor([-0.0054], grad_fn=<DivBackward0>)\n",
      "episode:  41  loss:  tensor([-1.1565e-08], grad_fn=<DivBackward0>)\n",
      "episode:  42  loss:  tensor([-0.0013], grad_fn=<DivBackward0>)\n",
      "episode:  43  loss:  tensor([-0.0036], grad_fn=<DivBackward0>)\n",
      "episode:  44  loss:  tensor([-0.0049], grad_fn=<DivBackward0>)\n",
      "episode:  45  loss:  tensor([-0.0029], grad_fn=<DivBackward0>)\n",
      "episode:  46  loss:  tensor([-0.0192], grad_fn=<DivBackward0>)\n",
      "episode:  47  loss:  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  48  loss:  tensor([-0.0118], grad_fn=<DivBackward0>)\n",
      "episode:  49  loss:  tensor([0.0106], grad_fn=<DivBackward0>)\n",
      "episode:  50  loss:  tensor([-0.0299], grad_fn=<DivBackward0>)\n",
      "episode:  51  loss:  tensor([1.7576e-08], grad_fn=<DivBackward0>)\n",
      "episode:  52  loss:  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  53  loss:  tensor([-0.0084], grad_fn=<DivBackward0>)\n",
      "episode:  54  loss:  tensor([-0.0117], grad_fn=<DivBackward0>)\n",
      "episode:  55  loss:  tensor([-0.0221], grad_fn=<DivBackward0>)\n",
      "episode:  56  loss:  tensor([0.0060], grad_fn=<DivBackward0>)\n",
      "episode:  57  loss:  tensor([-0.0138], grad_fn=<DivBackward0>)\n",
      "episode:  58  loss:  tensor([-0.0394], grad_fn=<DivBackward0>)\n",
      "episode:  59  loss:  tensor([-0.0415], grad_fn=<DivBackward0>)\n",
      "episode:  60  loss:  tensor([-0.0052], grad_fn=<DivBackward0>)\n",
      "episode:  61  loss:  tensor([2.6739e-08], grad_fn=<DivBackward0>)\n",
      "episode:  62  loss:  tensor([0.0059], grad_fn=<DivBackward0>)\n",
      "episode:  63  loss:  tensor([-0.0080], grad_fn=<DivBackward0>)\n",
      "episode:  64  loss:  tensor([-0.0039], grad_fn=<DivBackward0>)\n",
      "episode:  65  loss:  tensor([0.0123], grad_fn=<DivBackward0>)\n",
      "episode:  66  loss:  tensor([-0.0174], grad_fn=<DivBackward0>)\n",
      "episode:  67  loss:  tensor([-0.0220], grad_fn=<DivBackward0>)\n",
      "episode:  68  loss:  tensor([-0.0049], grad_fn=<DivBackward0>)\n",
      "episode:  69  loss:  tensor([-0.0138], grad_fn=<DivBackward0>)\n",
      "episode:  70  loss:  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "episode:  71  loss:  tensor([4.4674e-08], grad_fn=<DivBackward0>)\n",
      "episode:  72  loss:  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  73  loss:  tensor([0.0024], grad_fn=<DivBackward0>)\n",
      "episode:  74  loss:  tensor([-0.0048], grad_fn=<DivBackward0>)\n",
      "episode:  75  loss:  tensor([0.0067], grad_fn=<DivBackward0>)\n",
      "episode:  76  loss:  tensor([0.0074], grad_fn=<DivBackward0>)\n",
      "episode:  77  loss:  tensor([0.0604], grad_fn=<DivBackward0>)\n",
      "episode:  78  loss:  tensor([-0.0042], grad_fn=<DivBackward0>)\n",
      "episode:  79  loss:  tensor([-0.0067], grad_fn=<DivBackward0>)\n",
      "episode:  80  loss:  tensor([0.0413], grad_fn=<DivBackward0>)\n",
      "episode:  81  loss:  tensor([4.3162e-08], grad_fn=<DivBackward0>)\n",
      "episode:  82  loss:  tensor([-0.0263], grad_fn=<DivBackward0>)\n",
      "episode:  83  loss:  tensor([0.0318], grad_fn=<DivBackward0>)\n",
      "episode:  84  loss:  tensor([0.0580], grad_fn=<DivBackward0>)\n",
      "episode:  85  loss:  tensor([-0.0113], grad_fn=<DivBackward0>)\n",
      "episode:  86  loss:  tensor([-0.0015], grad_fn=<DivBackward0>)\n",
      "episode:  87  loss:  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "episode:  88  loss:  tensor([0.0139], grad_fn=<DivBackward0>)\n",
      "episode:  89  loss:  tensor([0.0084], grad_fn=<DivBackward0>)\n",
      "episode:  90  loss:  tensor([-0.0133], grad_fn=<DivBackward0>)\n",
      "episode:  91  loss:  tensor([1.4218e-07], grad_fn=<DivBackward0>)\n",
      "episode:  92  loss:  tensor([0.0050], grad_fn=<DivBackward0>)\n",
      "episode:  93  loss:  tensor([0.0130], grad_fn=<DivBackward0>)\n",
      "episode:  94  loss:  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  95  loss:  tensor([-0.0192], grad_fn=<DivBackward0>)\n",
      "episode:  96  loss:  tensor([0.0265], grad_fn=<DivBackward0>)\n",
      "episode:  97  loss:  tensor([0.0486], grad_fn=<DivBackward0>)\n",
      "episode:  98  loss:  tensor([0.0031], grad_fn=<DivBackward0>)\n",
      "episode:  99  loss:  tensor([0.0026], grad_fn=<DivBackward0>)\n",
      "episode:  100  loss:  tensor([-0.0061], grad_fn=<DivBackward0>)\n",
      "episode:  101  loss:  tensor([-8.6784e-08], grad_fn=<DivBackward0>)\n",
      "episode:  102  loss:  tensor([0.0676], grad_fn=<DivBackward0>)\n",
      "episode:  103  loss:  tensor([0.0088], grad_fn=<DivBackward0>)\n",
      "episode:  104  loss:  tensor([0.0191], grad_fn=<DivBackward0>)\n",
      "episode:  105  loss:  tensor([-0.0193], grad_fn=<DivBackward0>)\n",
      "episode:  106  loss:  tensor([0.0894], grad_fn=<DivBackward0>)\n",
      "episode:  107  loss:  tensor([0.0434], grad_fn=<DivBackward0>)\n",
      "episode:  108  loss:  tensor([-0.0080], grad_fn=<DivBackward0>)\n",
      "episode:  109  loss:  tensor([0.1210], grad_fn=<DivBackward0>)\n",
      "episode:  110  loss:  tensor([0.1366], grad_fn=<DivBackward0>)\n",
      "episode:  111  loss:  tensor([-3.5221e-08], grad_fn=<DivBackward0>)\n",
      "episode:  112  loss:  tensor([0.0126], grad_fn=<DivBackward0>)\n",
      "episode:  113  loss:  tensor([0.0865], grad_fn=<DivBackward0>)\n",
      "episode:  114  loss:  tensor([0.1008], grad_fn=<DivBackward0>)\n",
      "episode:  115  loss:  tensor([0.0040], grad_fn=<DivBackward0>)\n",
      "episode:  116  loss:  tensor([0.0164], grad_fn=<DivBackward0>)\n",
      "episode:  117  loss:  tensor([0.0196], grad_fn=<DivBackward0>)\n",
      "episode:  118  loss:  tensor([0.1450], grad_fn=<DivBackward0>)\n",
      "episode:  119  loss:  tensor([0.0832], grad_fn=<DivBackward0>)\n",
      "episode:  120  loss:  tensor([0.0090], grad_fn=<DivBackward0>)\n",
      "episode:  121  loss:  tensor([-2.4736e-08], grad_fn=<DivBackward0>)\n",
      "episode:  122  loss:  tensor([0.0173], grad_fn=<DivBackward0>)\n",
      "episode:  123  loss:  tensor([0.0835], grad_fn=<DivBackward0>)\n",
      "episode:  124  loss:  tensor([0.0239], grad_fn=<DivBackward0>)\n",
      "episode:  125  loss:  tensor([0.0188], grad_fn=<DivBackward0>)\n",
      "episode:  126  loss:  tensor([0.0467], grad_fn=<DivBackward0>)\n",
      "episode:  127  loss:  tensor([-0.0190], grad_fn=<DivBackward0>)\n",
      "episode:  128  loss:  tensor([-0.0099], grad_fn=<DivBackward0>)\n",
      "episode:  129  loss:  tensor([0.0660], grad_fn=<DivBackward0>)\n",
      "episode:  130  loss:  tensor([0.0613], grad_fn=<DivBackward0>)\n",
      "episode:  131  loss:  tensor([3.0089e-08], grad_fn=<DivBackward0>)\n",
      "episode:  132  loss:  tensor([0.0212], grad_fn=<DivBackward0>)\n",
      "episode:  133  loss:  tensor([0.0203], grad_fn=<DivBackward0>)\n",
      "episode:  134  loss:  tensor([-0.0027], grad_fn=<DivBackward0>)\n",
      "episode:  135  loss:  tensor([-0.0009], grad_fn=<DivBackward0>)\n",
      "episode:  136  loss:  tensor([-0.0032], grad_fn=<DivBackward0>)\n",
      "episode:  137  loss:  tensor([-0.0053], grad_fn=<DivBackward0>)\n",
      "episode:  138  loss:  tensor([-0.0103], grad_fn=<DivBackward0>)\n",
      "episode:  139  loss:  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "episode:  140  loss:  tensor([0.0050], grad_fn=<DivBackward0>)\n",
      "episode:  141  loss:  tensor([3.9886e-08], grad_fn=<DivBackward0>)\n",
      "episode:  142  loss:  tensor([0.0033], grad_fn=<DivBackward0>)\n",
      "episode:  143  loss:  tensor([0.0055], grad_fn=<DivBackward0>)\n",
      "episode:  144  loss:  tensor([0.0061], grad_fn=<DivBackward0>)\n",
      "episode:  145  loss:  tensor([0.0025], grad_fn=<DivBackward0>)\n",
      "episode:  146  loss:  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  147  loss:  tensor([0.0259], grad_fn=<DivBackward0>)\n",
      "episode:  148  loss:  tensor([-0.0129], grad_fn=<DivBackward0>)\n",
      "episode:  149  loss:  tensor([-0.0133], grad_fn=<DivBackward0>)\n",
      "episode:  150  loss:  tensor([-0.0015], grad_fn=<DivBackward0>)\n",
      "episode:  151  loss:  tensor([2.1706e-08], grad_fn=<DivBackward0>)\n",
      "episode:  152  loss:  tensor([-0.0024], grad_fn=<DivBackward0>)\n",
      "episode:  153  loss:  tensor([-0.0036], grad_fn=<DivBackward0>)\n",
      "episode:  154  loss:  tensor([-0.0111], grad_fn=<DivBackward0>)\n",
      "episode:  155  loss:  tensor([0.0553], grad_fn=<DivBackward0>)\n",
      "episode:  156  loss:  tensor([-0.0017], grad_fn=<DivBackward0>)\n",
      "episode:  157  loss:  tensor([0.0440], grad_fn=<DivBackward0>)\n",
      "episode:  158  loss:  tensor([0.0482], grad_fn=<DivBackward0>)\n",
      "episode:  159  loss:  tensor([0.0661], grad_fn=<DivBackward0>)\n",
      "episode:  160  loss:  tensor([0.0407], grad_fn=<DivBackward0>)\n",
      "episode:  161  loss:  tensor([4.0539e-08], grad_fn=<DivBackward0>)\n",
      "episode:  162  loss:  tensor([0.0059], grad_fn=<DivBackward0>)\n",
      "episode:  163  loss:  tensor([0.0023], grad_fn=<DivBackward0>)\n",
      "episode:  164  loss:  tensor([0.0050], grad_fn=<DivBackward0>)\n",
      "episode:  165  loss:  tensor([0.0180], grad_fn=<DivBackward0>)\n",
      "episode:  166  loss:  tensor([-0.0024], grad_fn=<DivBackward0>)\n",
      "episode:  167  loss:  tensor([0.0168], grad_fn=<DivBackward0>)\n",
      "episode:  168  loss:  tensor([0.0307], grad_fn=<DivBackward0>)\n",
      "episode:  169  loss:  tensor([0.0571], grad_fn=<DivBackward0>)\n",
      "episode:  170  loss:  tensor([0.0381], grad_fn=<DivBackward0>)\n",
      "episode:  171  loss:  tensor([-8.4642e-08], grad_fn=<DivBackward0>)\n",
      "episode:  172  loss:  tensor([0.0041], grad_fn=<DivBackward0>)\n",
      "episode:  173  loss:  tensor([-0.0054], grad_fn=<DivBackward0>)\n",
      "episode:  174  loss:  tensor([0.0054], grad_fn=<DivBackward0>)\n",
      "episode:  175  loss:  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "episode:  176  loss:  tensor([-0.0021], grad_fn=<DivBackward0>)\n",
      "episode:  177  loss:  tensor([-0.0034], grad_fn=<DivBackward0>)\n",
      "episode:  178  loss:  tensor([-3.0019e-05], grad_fn=<DivBackward0>)\n",
      "episode:  179  loss:  tensor([0.0042], grad_fn=<DivBackward0>)\n",
      "episode:  180  loss:  tensor([0.0107], grad_fn=<DivBackward0>)\n",
      "episode:  181  loss:  tensor([-9.6351e-08], grad_fn=<DivBackward0>)\n",
      "episode:  182  loss:  tensor([-0.0055], grad_fn=<DivBackward0>)\n",
      "episode:  183  loss:  tensor([0.0472], grad_fn=<DivBackward0>)\n",
      "episode:  184  loss:  tensor([0.0062], grad_fn=<DivBackward0>)\n",
      "episode:  185  loss:  tensor([0.0226], grad_fn=<DivBackward0>)\n",
      "episode:  186  loss:  tensor([0.0306], grad_fn=<DivBackward0>)\n",
      "episode:  187  loss:  tensor([0.0029], grad_fn=<DivBackward0>)\n",
      "episode:  188  loss:  tensor([0.0032], grad_fn=<DivBackward0>)\n",
      "episode:  189  loss:  tensor([0.0580], grad_fn=<DivBackward0>)\n",
      "episode:  190  loss:  tensor([-0.0166], grad_fn=<DivBackward0>)\n",
      "episode:  191  loss:  tensor([-1.7120e-07], grad_fn=<DivBackward0>)\n",
      "episode:  192  loss:  tensor([0.0044], grad_fn=<DivBackward0>)\n",
      "episode:  193  loss:  tensor([0.0298], grad_fn=<DivBackward0>)\n",
      "episode:  194  loss:  tensor([-0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  195  loss:  tensor([0.0107], grad_fn=<DivBackward0>)\n",
      "episode:  196  loss:  tensor([0.0228], grad_fn=<DivBackward0>)\n",
      "episode:  197  loss:  tensor([0.0625], grad_fn=<DivBackward0>)\n",
      "episode:  198  loss:  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  199  loss:  tensor([0.0299], grad_fn=<DivBackward0>)\n",
      "episode:  200  loss:  tensor([0.0088], grad_fn=<DivBackward0>)\n",
      "episode:  201  loss:  tensor([8.8446e-08], grad_fn=<DivBackward0>)\n",
      "episode:  202  loss:  tensor([0.0042], grad_fn=<DivBackward0>)\n",
      "episode:  203  loss:  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "episode:  204  loss:  tensor([0.0202], grad_fn=<DivBackward0>)\n",
      "episode:  205  loss:  tensor([-0.0047], grad_fn=<DivBackward0>)\n",
      "episode:  206  loss:  tensor([-0.0017], grad_fn=<DivBackward0>)\n",
      "episode:  207  loss:  tensor([0.0272], grad_fn=<DivBackward0>)\n",
      "episode:  208  loss:  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  209  loss:  tensor([-0.0066], grad_fn=<DivBackward0>)\n",
      "episode:  210  loss:  tensor([0.0311], grad_fn=<DivBackward0>)\n",
      "episode:  211  loss:  tensor([-2.0300e-08], grad_fn=<DivBackward0>)\n",
      "episode:  212  loss:  tensor([0.0237], grad_fn=<DivBackward0>)\n",
      "episode:  213  loss:  tensor([0.0067], grad_fn=<DivBackward0>)\n",
      "episode:  214  loss:  tensor([-0.0084], grad_fn=<DivBackward0>)\n",
      "episode:  215  loss:  tensor([0.0250], grad_fn=<DivBackward0>)\n",
      "episode:  216  loss:  tensor([0.0094], grad_fn=<DivBackward0>)\n",
      "episode:  217  loss:  tensor([0.0051], grad_fn=<DivBackward0>)\n",
      "episode:  218  loss:  tensor([0.0023], grad_fn=<DivBackward0>)\n",
      "episode:  219  loss:  tensor([0.0124], grad_fn=<DivBackward0>)\n",
      "episode:  220  loss:  tensor([0.0109], grad_fn=<DivBackward0>)\n",
      "episode:  221  loss:  tensor([-6.0170e-08], grad_fn=<DivBackward0>)\n",
      "episode:  222  loss:  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  223  loss:  tensor([-0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  224  loss:  tensor([0.0060], grad_fn=<DivBackward0>)\n",
      "episode:  225  loss:  tensor([-0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  226  loss:  tensor([0.0216], grad_fn=<DivBackward0>)\n",
      "episode:  227  loss:  tensor([0.0596], grad_fn=<DivBackward0>)\n",
      "episode:  228  loss:  tensor([0.0148], grad_fn=<DivBackward0>)\n",
      "episode:  229  loss:  tensor([0.0065], grad_fn=<DivBackward0>)\n",
      "episode:  230  loss:  tensor([0.0210], grad_fn=<DivBackward0>)\n",
      "episode:  231  loss:  tensor([-5.2118e-08], grad_fn=<DivBackward0>)\n",
      "episode:  232  loss:  tensor([0.0093], grad_fn=<DivBackward0>)\n",
      "episode:  233  loss:  tensor([-5.9834e-05], grad_fn=<DivBackward0>)\n",
      "episode:  234  loss:  tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "episode:  235  loss:  tensor([0.0336], grad_fn=<DivBackward0>)\n",
      "episode:  236  loss:  tensor([0.0119], grad_fn=<DivBackward0>)\n",
      "episode:  237  loss:  tensor([0.0101], grad_fn=<DivBackward0>)\n",
      "episode:  238  loss:  tensor([0.0088], grad_fn=<DivBackward0>)\n",
      "episode:  239  loss:  tensor([-0.0028], grad_fn=<DivBackward0>)\n",
      "episode:  240  loss:  tensor([0.0170], grad_fn=<DivBackward0>)\n",
      "episode:  241  loss:  tensor([1.5335e-07], grad_fn=<DivBackward0>)\n",
      "episode:  242  loss:  tensor([0.0043], grad_fn=<DivBackward0>)\n",
      "episode:  243  loss:  tensor([0.0108], grad_fn=<DivBackward0>)\n",
      "episode:  244  loss:  tensor([-0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  245  loss:  tensor([0.0159], grad_fn=<DivBackward0>)\n",
      "episode:  246  loss:  tensor([0.0442], grad_fn=<DivBackward0>)\n",
      "episode:  247  loss:  tensor([0.0786], grad_fn=<DivBackward0>)\n",
      "episode:  248  loss:  tensor([0.0034], grad_fn=<DivBackward0>)\n",
      "episode:  249  loss:  tensor([0.0138], grad_fn=<DivBackward0>)\n",
      "episode:  250  loss:  tensor([0.0275], grad_fn=<DivBackward0>)\n",
      "episode:  251  loss:  tensor([7.0581e-08], grad_fn=<DivBackward0>)\n",
      "episode:  252  loss:  tensor([0.0103], grad_fn=<DivBackward0>)\n",
      "episode:  253  loss:  tensor([-0.0022], grad_fn=<DivBackward0>)\n",
      "episode:  254  loss:  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  255  loss:  tensor([0.0041], grad_fn=<DivBackward0>)\n",
      "episode:  256  loss:  tensor([0.0021], grad_fn=<DivBackward0>)\n",
      "episode:  257  loss:  tensor([0.0051], grad_fn=<DivBackward0>)\n",
      "episode:  258  loss:  tensor([0.0027], grad_fn=<DivBackward0>)\n",
      "episode:  259  loss:  tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "episode:  260  loss:  tensor([0.0023], grad_fn=<DivBackward0>)\n",
      "episode:  261  loss:  tensor([-1.0663e-07], grad_fn=<DivBackward0>)\n",
      "episode:  262  loss:  tensor([0.0049], grad_fn=<DivBackward0>)\n",
      "episode:  263  loss:  tensor([0.0066], grad_fn=<DivBackward0>)\n",
      "episode:  264  loss:  tensor([-0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  265  loss:  tensor([4.9715e-06], grad_fn=<DivBackward0>)\n",
      "episode:  266  loss:  tensor([0.0114], grad_fn=<DivBackward0>)\n",
      "episode:  267  loss:  tensor([-0.0018], grad_fn=<DivBackward0>)\n",
      "episode:  268  loss:  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  269  loss:  tensor([-0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  270  loss:  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  271  loss:  tensor([7.0379e-08], grad_fn=<DivBackward0>)\n",
      "episode:  272  loss:  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  273  loss:  tensor([0.0753], grad_fn=<DivBackward0>)\n",
      "episode:  274  loss:  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  275  loss:  tensor([0.4816], grad_fn=<DivBackward0>)\n",
      "episode:  276  loss:  tensor([0.3746], grad_fn=<DivBackward0>)\n",
      "episode:  277  loss:  tensor([1.4790], grad_fn=<DivBackward0>)\n",
      "episode:  278  loss:  tensor([0.0101], grad_fn=<DivBackward0>)\n",
      "episode:  279  loss:  tensor([5.5495], grad_fn=<DivBackward0>)\n",
      "episode:  280  loss:  tensor([0.1933], grad_fn=<DivBackward0>)\n",
      "episode:  281  loss:  tensor([-2.7384e-07], grad_fn=<DivBackward0>)\n",
      "episode:  282  loss:  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "episode:  283  loss:  tensor([0.0312], grad_fn=<DivBackward0>)\n",
      "episode:  284  loss:  tensor([0.2662], grad_fn=<DivBackward0>)\n",
      "episode:  285  loss:  tensor([0.0947], grad_fn=<DivBackward0>)\n",
      "episode:  286  loss:  tensor([-0.0097], grad_fn=<DivBackward0>)\n",
      "episode:  287  loss:  tensor([0.0792], grad_fn=<DivBackward0>)\n",
      "episode:  288  loss:  tensor([0.0404], grad_fn=<DivBackward0>)\n",
      "episode:  289  loss:  tensor([0.0101], grad_fn=<DivBackward0>)\n",
      "episode:  290  loss:  tensor([0.0595], grad_fn=<DivBackward0>)\n",
      "episode:  291  loss:  tensor([-7.7211e-08], grad_fn=<DivBackward0>)\n",
      "episode:  292  loss:  tensor([-0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  293  loss:  tensor([-0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  294  loss:  tensor([0.0040], grad_fn=<DivBackward0>)\n",
      "episode:  295  loss:  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "episode:  296  loss:  tensor([-0.0102], grad_fn=<DivBackward0>)\n",
      "episode:  297  loss:  tensor([-0.0018], grad_fn=<DivBackward0>)\n",
      "episode:  298  loss:  tensor([0.0043], grad_fn=<DivBackward0>)\n",
      "episode:  299  loss:  tensor([0.0050], grad_fn=<DivBackward0>)\n",
      "episode:  300  loss:  tensor([0.0098], grad_fn=<DivBackward0>)\n",
      "episode:  301  loss:  tensor([1.0846e-07], grad_fn=<DivBackward0>)\n",
      "episode:  302  loss:  tensor([-0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  303  loss:  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  304  loss:  tensor([0.0052], grad_fn=<DivBackward0>)\n",
      "episode:  305  loss:  tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "episode:  306  loss:  tensor([-0.0097], grad_fn=<DivBackward0>)\n",
      "episode:  307  loss:  tensor([0.0055], grad_fn=<DivBackward0>)\n",
      "episode:  308  loss:  tensor([0.0137], grad_fn=<DivBackward0>)\n",
      "episode:  309  loss:  tensor([-0.0026], grad_fn=<DivBackward0>)\n",
      "episode:  310  loss:  tensor([-0.0041], grad_fn=<DivBackward0>)\n",
      "episode:  311  loss:  tensor([7.1723e-08], grad_fn=<DivBackward0>)\n",
      "episode:  312  loss:  tensor([-0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  313  loss:  tensor([-0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  314  loss:  tensor([0.0060], grad_fn=<DivBackward0>)\n",
      "episode:  315  loss:  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "episode:  316  loss:  tensor([-0.0018], grad_fn=<DivBackward0>)\n",
      "episode:  317  loss:  tensor([-0.0040], grad_fn=<DivBackward0>)\n",
      "episode:  318  loss:  tensor([-0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  319  loss:  tensor([-0.0026], grad_fn=<DivBackward0>)\n",
      "episode:  320  loss:  tensor([0.0068], grad_fn=<DivBackward0>)\n",
      "episode:  321  loss:  tensor([-5.0897e-08], grad_fn=<DivBackward0>)\n",
      "episode:  322  loss:  tensor([-7.6827e-05], grad_fn=<DivBackward0>)\n",
      "episode:  323  loss:  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  324  loss:  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  325  loss:  tensor([-0.0016], grad_fn=<DivBackward0>)\n",
      "episode:  326  loss:  tensor([-0.0052], grad_fn=<DivBackward0>)\n",
      "episode:  327  loss:  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  328  loss:  tensor([0.0055], grad_fn=<DivBackward0>)\n",
      "episode:  329  loss:  tensor([0.0070], grad_fn=<DivBackward0>)\n",
      "episode:  330  loss:  tensor([0.0100], grad_fn=<DivBackward0>)\n",
      "episode:  331  loss:  tensor([7.0479e-08], grad_fn=<DivBackward0>)\n",
      "episode:  332  loss:  tensor([0.0064], grad_fn=<DivBackward0>)\n",
      "episode:  333  loss:  tensor([0.0091], grad_fn=<DivBackward0>)\n",
      "episode:  334  loss:  tensor([0.0072], grad_fn=<DivBackward0>)\n",
      "episode:  335  loss:  tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "episode:  336  loss:  tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "episode:  337  loss:  tensor([0.0021], grad_fn=<DivBackward0>)\n",
      "episode:  338  loss:  tensor([-0.0031], grad_fn=<DivBackward0>)\n",
      "episode:  339  loss:  tensor([0.0203], grad_fn=<DivBackward0>)\n",
      "episode:  340  loss:  tensor([0.0053], grad_fn=<DivBackward0>)\n",
      "episode:  341  loss:  tensor([9.7164e-08], grad_fn=<DivBackward0>)\n",
      "episode:  342  loss:  tensor([0.0039], grad_fn=<DivBackward0>)\n",
      "episode:  343  loss:  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  344  loss:  tensor([-0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  345  loss:  tensor([-0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  346  loss:  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  347  loss:  tensor([-0.0048], grad_fn=<DivBackward0>)\n",
      "episode:  348  loss:  tensor([0.0029], grad_fn=<DivBackward0>)\n",
      "episode:  349  loss:  tensor([0.0033], grad_fn=<DivBackward0>)\n",
      "episode:  350  loss:  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  351  loss:  tensor([-1.2198e-08], grad_fn=<DivBackward0>)\n",
      "episode:  352  loss:  tensor([-0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  353  loss:  tensor([-0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  354  loss:  tensor([-0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  355  loss:  tensor([-0.0090], grad_fn=<DivBackward0>)\n",
      "episode:  356  loss:  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "episode:  357  loss:  tensor([1.6167e-05], grad_fn=<DivBackward0>)\n",
      "episode:  358  loss:  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  359  loss:  tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "episode:  360  loss:  tensor([3.1951e-05], grad_fn=<DivBackward0>)\n",
      "episode:  361  loss:  tensor([1.9816e-07], grad_fn=<DivBackward0>)\n",
      "episode:  362  loss:  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  363  loss:  tensor([-0.0003], grad_fn=<DivBackward0>)\n",
      "episode:  364  loss:  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "episode:  365  loss:  tensor([-0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  366  loss:  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  367  loss:  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  368  loss:  tensor([-0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  369  loss:  tensor([0.0119], grad_fn=<DivBackward0>)\n",
      "episode:  370  loss:  tensor([0.0012], grad_fn=<DivBackward0>)\n",
      "episode:  371  loss:  tensor([-9.9851e-08], grad_fn=<DivBackward0>)\n",
      "episode:  372  loss:  tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "episode:  373  loss:  tensor([-0.0001], grad_fn=<DivBackward0>)\n",
      "episode:  374  loss:  tensor([0.0036], grad_fn=<DivBackward0>)\n",
      "episode:  375  loss:  tensor([-0.0013], grad_fn=<DivBackward0>)\n",
      "episode:  376  loss:  tensor([0.0061], grad_fn=<DivBackward0>)\n",
      "episode:  377  loss:  tensor([0.0063], grad_fn=<DivBackward0>)\n",
      "episode:  378  loss:  tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "episode:  379  loss:  tensor([0.0055], grad_fn=<DivBackward0>)\n",
      "episode:  380  loss:  tensor([-0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  381  loss:  tensor([1.5766e-07], grad_fn=<DivBackward0>)\n",
      "episode:  382  loss:  tensor([-0.0016], grad_fn=<DivBackward0>)\n",
      "episode:  383  loss:  tensor([-0.0034], grad_fn=<DivBackward0>)\n",
      "episode:  384  loss:  tensor([-6.1670e-05], grad_fn=<DivBackward0>)\n",
      "episode:  385  loss:  tensor([-0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  386  loss:  tensor([-0.0031], grad_fn=<DivBackward0>)\n",
      "episode:  387  loss:  tensor([0.0029], grad_fn=<DivBackward0>)\n",
      "episode:  388  loss:  tensor([-0.0037], grad_fn=<DivBackward0>)\n",
      "episode:  389  loss:  tensor([0.0033], grad_fn=<DivBackward0>)\n",
      "episode:  390  loss:  tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "episode:  391  loss:  tensor([6.0386e-08], grad_fn=<DivBackward0>)\n",
      "episode:  392  loss:  tensor([-0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  393  loss:  tensor([0.0022], grad_fn=<DivBackward0>)\n",
      "episode:  394  loss:  tensor([-0.0062], grad_fn=<DivBackward0>)\n",
      "episode:  395  loss:  tensor([0.0065], grad_fn=<DivBackward0>)\n",
      "episode:  396  loss:  tensor([0.0029], grad_fn=<DivBackward0>)\n",
      "episode:  397  loss:  tensor([0.0014], grad_fn=<DivBackward0>)\n",
      "episode:  398  loss:  tensor([-0.0013], grad_fn=<DivBackward0>)\n",
      "episode:  399  loss:  tensor([0.0041], grad_fn=<DivBackward0>)\n",
      "episode:  400  loss:  tensor([-0.0031], grad_fn=<DivBackward0>)\n",
      "episode:  401  loss:  tensor([-6.5991e-09], grad_fn=<DivBackward0>)\n",
      "episode:  402  loss:  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  403  loss:  tensor([0.0037], grad_fn=<DivBackward0>)\n",
      "episode:  404  loss:  tensor([-0.0003], grad_fn=<DivBackward0>)\n",
      "episode:  405  loss:  tensor([-0.0015], grad_fn=<DivBackward0>)\n",
      "episode:  406  loss:  tensor([-0.0028], grad_fn=<DivBackward0>)\n",
      "episode:  407  loss:  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  408  loss:  tensor([-0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  409  loss:  tensor([0.0105], grad_fn=<DivBackward0>)\n",
      "episode:  410  loss:  tensor([-0.0037], grad_fn=<DivBackward0>)\n",
      "episode:  411  loss:  tensor([-2.6678e-08], grad_fn=<DivBackward0>)\n",
      "episode:  412  loss:  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  413  loss:  tensor([-0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  414  loss:  tensor([-0.0045], grad_fn=<DivBackward0>)\n",
      "episode:  415  loss:  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  416  loss:  tensor([0.0075], grad_fn=<DivBackward0>)\n",
      "episode:  417  loss:  tensor([0.0021], grad_fn=<DivBackward0>)\n",
      "episode:  418  loss:  tensor([-0.0116], grad_fn=<DivBackward0>)\n",
      "episode:  419  loss:  tensor([-0.0014], grad_fn=<DivBackward0>)\n",
      "episode:  420  loss:  tensor([-0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  421  loss:  tensor([-7.9622e-08], grad_fn=<DivBackward0>)\n",
      "episode:  422  loss:  tensor([-2.9310e-05], grad_fn=<DivBackward0>)\n",
      "episode:  423  loss:  tensor([0.0072], grad_fn=<DivBackward0>)\n",
      "episode:  424  loss:  tensor([0.0109], grad_fn=<DivBackward0>)\n",
      "episode:  425  loss:  tensor([-0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  426  loss:  tensor([-0.0064], grad_fn=<DivBackward0>)\n",
      "episode:  427  loss:  tensor([-0.0031], grad_fn=<DivBackward0>)\n",
      "episode:  428  loss:  tensor([0.0035], grad_fn=<DivBackward0>)\n",
      "episode:  429  loss:  tensor([-0.0045], grad_fn=<DivBackward0>)\n",
      "episode:  430  loss:  tensor([-0.0034], grad_fn=<DivBackward0>)\n",
      "episode:  431  loss:  tensor([-2.4259e-07], grad_fn=<DivBackward0>)\n",
      "episode:  432  loss:  tensor([-0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  433  loss:  tensor([-0.0023], grad_fn=<DivBackward0>)\n",
      "episode:  434  loss:  tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "episode:  435  loss:  tensor([9.7315e-05], grad_fn=<DivBackward0>)\n",
      "episode:  436  loss:  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  437  loss:  tensor([-0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  438  loss:  tensor([-0.0001], grad_fn=<DivBackward0>)\n",
      "episode:  439  loss:  tensor([0.0058], grad_fn=<DivBackward0>)\n",
      "episode:  440  loss:  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  441  loss:  tensor([1.6148e-07], grad_fn=<DivBackward0>)\n",
      "episode:  442  loss:  tensor([-2.5088e-05], grad_fn=<DivBackward0>)\n",
      "episode:  443  loss:  tensor([0.0018], grad_fn=<DivBackward0>)\n",
      "episode:  444  loss:  tensor([-0.0003], grad_fn=<DivBackward0>)\n",
      "episode:  445  loss:  tensor([-0.0021], grad_fn=<DivBackward0>)\n",
      "episode:  446  loss:  tensor([0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  447  loss:  tensor([0.0023], grad_fn=<DivBackward0>)\n",
      "episode:  448  loss:  tensor([0.0041], grad_fn=<DivBackward0>)\n",
      "episode:  449  loss:  tensor([0.0017], grad_fn=<DivBackward0>)\n",
      "episode:  450  loss:  tensor([-0.0001], grad_fn=<DivBackward0>)\n",
      "episode:  451  loss:  tensor([1.0345e-07], grad_fn=<DivBackward0>)\n",
      "episode:  452  loss:  tensor([9.7140e-05], grad_fn=<DivBackward0>)\n",
      "episode:  453  loss:  tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "episode:  454  loss:  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  455  loss:  tensor([-0.0015], grad_fn=<DivBackward0>)\n",
      "episode:  456  loss:  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  457  loss:  tensor([-0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  458  loss:  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "episode:  459  loss:  tensor([0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  460  loss:  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  461  loss:  tensor([-1.1670e-08], grad_fn=<DivBackward0>)\n",
      "episode:  462  loss:  tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "episode:  463  loss:  tensor([0.0024], grad_fn=<DivBackward0>)\n",
      "episode:  464  loss:  tensor([-0.0016], grad_fn=<DivBackward0>)\n",
      "episode:  465  loss:  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  466  loss:  tensor([-0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  467  loss:  tensor([0.0001], grad_fn=<DivBackward0>)\n",
      "episode:  468  loss:  tensor([-0.0012], grad_fn=<DivBackward0>)\n",
      "episode:  469  loss:  tensor([0.0024], grad_fn=<DivBackward0>)\n",
      "episode:  470  loss:  tensor([-0.0026], grad_fn=<DivBackward0>)\n",
      "episode:  471  loss:  tensor([-3.5298e-08], grad_fn=<DivBackward0>)\n",
      "episode:  472  loss:  tensor([-0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  473  loss:  tensor([0.0006], grad_fn=<DivBackward0>)\n",
      "episode:  474  loss:  tensor([-0.0003], grad_fn=<DivBackward0>)\n",
      "episode:  475  loss:  tensor([-0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  476  loss:  tensor([-0.0009], grad_fn=<DivBackward0>)\n",
      "episode:  477  loss:  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  478  loss:  tensor([-0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  479  loss:  tensor([2.6359e-05], grad_fn=<DivBackward0>)\n",
      "episode:  480  loss:  tensor([-0.0014], grad_fn=<DivBackward0>)\n",
      "episode:  481  loss:  tensor([-3.6344e-08], grad_fn=<DivBackward0>)\n",
      "episode:  482  loss:  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  483  loss:  tensor([-0.0047], grad_fn=<DivBackward0>)\n",
      "episode:  484  loss:  tensor([0.0020], grad_fn=<DivBackward0>)\n",
      "episode:  485  loss:  tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "episode:  486  loss:  tensor([0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  487  loss:  tensor([0.0016], grad_fn=<DivBackward0>)\n",
      "episode:  488  loss:  tensor([0.0173], grad_fn=<DivBackward0>)\n",
      "episode:  489  loss:  tensor([-0.0001], grad_fn=<DivBackward0>)\n",
      "episode:  490  loss:  tensor([-0.0007], grad_fn=<DivBackward0>)\n",
      "episode:  491  loss:  tensor([1.1649e-07], grad_fn=<DivBackward0>)\n",
      "episode:  492  loss:  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  493  loss:  tensor([0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  494  loss:  tensor([-0.0022], grad_fn=<DivBackward0>)\n",
      "episode:  495  loss:  tensor([0.0010], grad_fn=<DivBackward0>)\n",
      "episode:  496  loss:  tensor([-0.0009], grad_fn=<DivBackward0>)\n",
      "episode:  497  loss:  tensor([0.0005], grad_fn=<DivBackward0>)\n",
      "episode:  498  loss:  tensor([5.1251e-05], grad_fn=<DivBackward0>)\n",
      "episode:  499  loss:  tensor([-0.0008], grad_fn=<DivBackward0>)\n",
      "episode:  500  loss:  tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  501  loss:  tensor([2.1982e-07], grad_fn=<DivBackward0>)\n",
      "episode:  502  loss:  tensor([-0.0002], grad_fn=<DivBackward0>)\n",
      "episode:  503  loss:  tensor([-0.0004], grad_fn=<DivBackward0>)\n",
      "episode:  504  loss:  tensor([0.0009], grad_fn=<DivBackward0>)\n",
      "episode:  505  loss:  tensor([-0.0011], grad_fn=<DivBackward0>)\n",
      "episode:  506  loss:  tensor([-0.0022], grad_fn=<DivBackward0>)\n",
      "episode:  507  loss:  tensor([0.0049], grad_fn=<DivBackward0>)\n",
      "episode:  508  loss:  tensor([0.0023], grad_fn=<DivBackward0>)\n",
      "episode:  509  loss:  tensor([0.0007], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     75\u001b[39m current_log_probs = torch.log_softmax(current_logits,dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     77\u001b[39m current_confidence = current_log_probs[actions[i]] \n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m old_logits = \u001b[43moldPolicyModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m old_log_probs = torch.log_softmax(old_logits,dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     83\u001b[39m old_confidence = old_log_probs[actions[i]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mPolicy.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "def is_terminal(observation):\n",
    "    x,v,theta , omega = observation \n",
    "    x_terminal = x <= -4.8 or x>=4.8 \n",
    "    theta_terminal = theta <= -0.209*7.5 or theta >= 0.209*7.5\n",
    "    return x_terminal or theta_terminal\n",
    "\n",
    "\n",
    "episodes = 10000\n",
    "\n",
    "value_optimizer = torch.optim.Adam(valueModel.parameters(), lr=1e-3)\n",
    "policy_optimizer = torch.optim.Adam(policyModel.parameters(),lr=1e-3)\n",
    "valueLoss = torch.nn.functional.mse_loss\n",
    "gamma = 0.99\n",
    "epsilon =0.3\n",
    "update_old_step = 10\n",
    "update_old_policy() \n",
    "for episode in range(episodes):\n",
    "    done = False\n",
    "    obs, info = env.reset()\n",
    "    obs = torch.tensor(obs)\n",
    "    observations = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    confidences= []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        while not done:\n",
    "            \n",
    "            observations.append(obs)\n",
    "            logits = policyModel(obs)\n",
    "            probs = torch.softmax(logits,dim=-1)\n",
    "\n",
    "            action = torch.multinomial(probs, num_samples=1).item()\n",
    "            confidences.append(probs[action]) \n",
    "            actions.append(action) \n",
    "            obs, reward, terminated, truncated , info = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            obs = torch.tensor(obs)\n",
    "            done = is_terminal(obs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        discontinued_rewards = []\n",
    "        reward = 0 \n",
    "        observation_tensor = torch.stack(observations) \n",
    "        for i in range(-1,-len(rewards) -1,-1):\n",
    "            reward = rewards[i] + gamma * reward\n",
    "            discontinued_rewards.append(reward)\n",
    "\n",
    "\n",
    "        discontinued_rewards.reverse()\n",
    "        discontinued_rewards = torch.tensor(discontinued_rewards,dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    reward_preds = valueModel(observation_tensor)   \n",
    "    loss = valueLoss(reward_preds.squeeze(-1),discontinued_rewards)\n",
    "    value_optimizer.zero_grad()\n",
    "    loss.backward() \n",
    "    value_optimizer.step()\n",
    "    reward_preds = reward_preds.detach()\n",
    "    \n",
    "    total_loss = 0\n",
    "    advantages = []\n",
    "    for i in range(len(observations)):\n",
    "        predicted_reward = reward_preds[i]\n",
    "        reward = discontinued_rewards[i] \n",
    "        advantage = reward - predicted_reward  \n",
    "        advantages.append(advantage)\n",
    "    advantages = torch.stack(advantages) \n",
    "    advantages = (advantages - advantages.mean()) / (advantages.std(unbiased=False) + 1e-8)\n",
    "\n",
    "    for i in range(len(observations)):\n",
    "        advantage = advantages[i]  \n",
    "        current_logits = policyModel(observations[i])\n",
    "        current_log_probs = torch.log_softmax(current_logits,dim=-1)\n",
    "\n",
    "        current_confidence = current_log_probs[actions[i]] \n",
    "\n",
    "        old_logits = oldPolicyModel(observations[i])\n",
    "       \n",
    "        \n",
    "        old_log_probs = torch.log_softmax(old_logits,dim=-1)\n",
    "        old_confidence = old_log_probs[actions[i]]\n",
    "\n",
    "        confidence_ratio = torch.exp(current_confidence - old_confidence)\n",
    "        loss = confidence_ratio*advantage   \n",
    "        loss2 =torch.clip( (confidence_ratio) , 1-epsilon , 1+epsilon)*advantage \n",
    "        loss = -torch.min(loss, loss2)\n",
    "        \n",
    "        total_loss += loss \n",
    "    total_loss /= len(observations)\n",
    "    print('episode: ',episode + 1, ' loss: ',total_loss)\n",
    "    policy_optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    policy_optimizer.step()\n",
    "    if  (episode + 1)  % update_old_step == 0:\n",
    "        update_old_policy()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b4dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym \n",
    "\n",
    "\n",
    "\n",
    "env = gym.make(\"CartPole-v1\",render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0414ed5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:214: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode:  1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     17\u001b[39m confidences.append(probs[action])\n\u001b[32m     18\u001b[39m actions.append(action)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m obs, reward, terminated, truncated , info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m rewards.append(reward)\n\u001b[32m     21\u001b[39m obs = torch.tensor(obs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:125\u001b[39m, in \u001b[36mTimeLimit.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    114\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m \n\u001b[32m    124\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mself\u001b[39m._elapsed_steps += \u001b[32m1\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elapsed_steps >= \u001b[38;5;28mself\u001b[39m._max_episode_steps:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[39m, in \u001b[36mOrderEnforcing.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[33m\"\u001b[39m\u001b[33mCannot call env.step() before calling env.reset()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:285\u001b[39m, in \u001b[36mPassiveEnvChecker.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m.env, action)\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:223\u001b[39m, in \u001b[36mCartPoleEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    220\u001b[39m     reward = -\u001b[32m1.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sutton_barto_reward \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.render_mode == \u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# truncation=False as the time limit is handled by the `TimeLimit` wrapper added during `make`\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.array(\u001b[38;5;28mself\u001b[39m.state, dtype=np.float32), reward, terminated, \u001b[38;5;28;01mFalse\u001b[39;00m, {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\cartpole.py:337\u001b[39m, in \u001b[36mCartPoleEnv.render\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.render_mode == \u001b[33m\"\u001b[39m\u001b[33mhuman\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    336\u001b[39m     pygame.event.pump()\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrender_fps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     pygame.display.flip()\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.render_mode == \u001b[33m\"\u001b[39m\u001b[33mrgb_array\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for episode in range(episodes):\n",
    "    done = False\n",
    "    obs, info = env.reset(seed=42)\n",
    "    obs = torch.tensor(obs)\n",
    "    observations = []\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    confidences= []\n",
    "    with torch.no_grad():\n",
    "        while not done:\n",
    "            \n",
    "            observations.append(obs)\n",
    "            logits = policyModel(obs)\n",
    "            probs = torch.softmax(logits,dim=-1)\n",
    "\n",
    "            action = torch.multinomial(probs, num_samples=1).item()\n",
    "            confidences.append(probs[action])\n",
    "            actions.append(action)\n",
    "            obs, reward, terminated, truncated , info = env.step(action)\n",
    "            rewards.append(reward)\n",
    "            obs = torch.tensor(obs)\n",
    "            done = is_terminal(obs)\n",
    "        print('episode: ',episode + 1)\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2b5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
