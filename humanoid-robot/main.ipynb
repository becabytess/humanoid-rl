{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator\n",
    "import gymnasium as gym \n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "env = gym.make(\"Humanoid-v5\",render_mode='human')\n",
    "action_shape = env.action_space.shape[0]\n",
    "observation_shape = env.observation_space.shape[0]\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.logits = nn.Sequential(\n",
    "            nn.Linear(observation_shape,400),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(400,250),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(250,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,action_shape)\n",
    "        )\n",
    "    def forward(self,X):\n",
    "        logits = self.logits(X)\n",
    "        return logits \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Action dimension mismatch. Expected (17,), found ()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m probs = torch.softmax(logits,dim=-\u001b[32m1\u001b[39m)\n\u001b[32m     11\u001b[39m action = torch.multinomial(probs,num_samples=\u001b[32m1\u001b[39m).item()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m observation, reward , terminated , truncated , info  = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m observation = torch.tensor(observation,dtype=torch.float32)\n\u001b[32m     15\u001b[39m env.render()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:125\u001b[39m, in \u001b[36mTimeLimit.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: ActType\n\u001b[32m    114\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[ObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    115\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[32m    116\u001b[39m \n\u001b[32m    117\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m \n\u001b[32m    124\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     observation, reward, terminated, truncated, info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mself\u001b[39m._elapsed_steps += \u001b[32m1\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._elapsed_steps >= \u001b[38;5;28mself\u001b[39m._max_episode_steps:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[39m, in \u001b[36mOrderEnforcing.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    391\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_reset:\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[33m\"\u001b[39m\u001b[33mCannot call env.step() before calling env.reset()\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\core.py:327\u001b[39m, in \u001b[36mWrapper.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\n\u001b[32m    324\u001b[39m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[32m    325\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\wrappers\\common.py:283\u001b[39m, in \u001b[36mPassiveEnvChecker.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checked_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    282\u001b[39m     \u001b[38;5;28mself\u001b[39m.checked_step = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.step(action)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:207\u001b[39m, in \u001b[36menv_step_passive_checker\u001b[39m\u001b[34m(env, action)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m result = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    209\u001b[39m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    210\u001b[39m ), \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) == \u001b[32m4\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\humanoid_v5.py:476\u001b[39m, in \u001b[36mHumanoidEnv.step\u001b[39m\u001b[34m(self, action)\u001b[39m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[32m    475\u001b[39m     xy_position_before = mass_center(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.data)\n\u001b[32m--> \u001b[39m\u001b[32m476\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_simulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_skip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    477\u001b[39m     xy_position_after = mass_center(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.data)\n\u001b[32m    479\u001b[39m     xy_velocity = (xy_position_after - xy_position_before) / \u001b[38;5;28mself\u001b[39m.dt\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\beca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gymnasium\\envs\\mujoco\\mujoco_env.py:197\u001b[39m, in \u001b[36mMujocoEnv.do_simulation\u001b[39m\u001b[34m(self, ctrl, n_frames)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Check control input is contained in the action space\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.array(ctrl).shape != (\u001b[38;5;28mself\u001b[39m.model.nu,):\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    198\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAction dimension mismatch. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mself\u001b[39m.model.nu,)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp.array(ctrl).shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    199\u001b[39m     )\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m._step_mujoco_simulation(ctrl, n_frames)\n",
      "\u001b[31mValueError\u001b[39m: Action dimension mismatch. Expected (17,), found ()"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "observation,info = env.reset()\n",
    "observation = torch.tensor(observation,dtype=torch.float32)\n",
    "policy = Policy()\n",
    "\n",
    "\n",
    "\n",
    "for _ in range(1000):\n",
    "    print(_)\n",
    "    logits = policy(observation)\n",
    "    probs = torch.softmax(logits,dim=-1)\n",
    "    action = torch.multinomial(probs,num_samples=1).item()\n",
    "    observation, reward , terminated , truncated , info  = env.step(action)\n",
    "    observation = torch.tensor(observation,dtype=torch.float32)\n",
    "\n",
    "    env.render()\n",
    "    if terminated or truncated:\n",
    "        print('episode complete')\n",
    "        observation,info = env.reset()\n",
    "        observation = torch.tensor(observation,dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
